# -*- coding: utf-8 -*-
"""Outlier_Detection_Shalini_reecha_priynaka_akanksha.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uGEyaIC06pZ4ZBarZpbpLQIh2_9zvvnW

Loading the data
"""

import pandas as pd
df = pd.read_csv("data.csv")
df.shape

df.head()

"""Check for null Value"""

# There is no NA values.
df.count(axis = 0)

"""Remove last column "unamed 32" having all NAN values"""

df=df.drop(['Unnamed: 32'],axis=1)

df.head()

"""Visulaization before feature selection:"""

import matplotlib.pyplot as plt 
total_count =df['diagnosis'].value_counts()
print(total_count)
colors=['violet','pink']
activities = ['B','M '] 
plt.pie(total_count, labels = activities, colors=colors,  
        startangle=90, shadow = True, explode = (0, 0), 
        radius = 1.2, autopct = '%1.1f%%') 
plt.legend() 
plt.show()

"""Encode the class labels:"M" as 1 and "B" as 0"""

# label encode if Malignant then 1 else benign then 0;
Class=list(df['diagnosis'])
df=df.drop(['diagnosis'],axis=1)
def encoding_labels(Class):
  labels=[]
  for i in Class:
    if i=='M':
      labels.append(1)
    else:
      labels.append(0)
  return labels
encoded_labels=encoding_labels(Class)

df['class']=encoded_labels
df.shape

df.info()

# dataset visualization 
# Check pandas profiling
# plot histogram for each variable
import seaborn as sns
import matplotlib.pyplot as plt

sns.set(color_codes=True)
sns.set(style="white", palette="husl")
fig, ax = plt.subplots(figsize = (12,10))
for a in df.columns:
    sns.distplot(df[a].astype('float'), ax=ax, label = a)
ax.set_xlim(left = 0, right = 0.3)
ax.legend()
plt.show()

# https://seaborn.pydata.org/generated/seaborn.countplot.html

sns.set(style="darkgrid")
ax = sns.countplot(x="class", data=df)

# heat map to show the correlation between the columns

plt.figure(figsize=(30,20))
sns.heatmap(df.corr(),annot=True)
plt.ioff()

"""Removing one of the two highly correlated feature"""

import numpy as np
corr = df.corr()
columns = np.full((corr.shape[0],), True, dtype=bool)
for i in range(corr.shape[0]):
    for j in range(i+1, corr.shape[0]):
        if corr.iloc[i,j] >= 0.9:
            if columns[j]:
                columns[j] = False
selected_columns = df.columns[columns]
df = df[selected_columns]

#histogram for every attribute
df.hist(figsize = (20, 20))
plt.show()

"""Removing labels from the data"""

CLASS=df['class']
df=df.drop(['class'],axis=1)

df.shape

"""Detect Outliers"""

#df is Xtrain without label
from sklearn.ensemble import IsolationForest
clf=IsolationForest(n_estimators=100, max_samples='auto', contamination=float(.12), \
                        max_features=1.0, bootstrap=False, n_jobs=-1, random_state=42, verbose=0)
clf.fit(df)
pred = clf.predict(df)
df['anomaly']=pred
outliers=df.loc[df['anomaly']==-1]
outlier_index=list(outliers.index)
print(outlier_index)
#Find the number of anomalies and normal points here points classified -1 are anomalous
print(df['anomaly'].value_counts())

"""Remove Outliers"""

df=df.drop(outlier_index)
df=df.drop(['anomaly'],axis=1)
Class=[]
for i in range(len(CLASS)):
  if i not in outlier_index:
    Class.append(CLASS[i])
print(df.shape)
print(len(Class))

"""Test train split for final analysis:"""

# 20% train data and 80% test data
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(df,Class, test_size = 0.2, random_state = 0)

"""Remove id from the test and train data"""

id_test=X_test["id"]
df=df.drop(['id'],axis=1)
X_train=X_train.drop(['id'],axis=1)
X_test=X_test.drop(['id'],axis=1)

"""Standardize features by Standard Scalar"""

#removing the mean and scaling to unit variance
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

"""Removing Class imbalance from train data"""

from collections import Counter
from imblearn.over_sampling import SMOTE
from matplotlib import pyplot
from numpy import where
oversample = SMOTE()
X_train, y_train = oversample.fit_resample(X_train,y_train)

"""Scatter plot showing data distribution"""

counter = Counter(y_train)
print(counter)
for label, _ in counter.items():
	row_ix = where(y_train == label)[0]
	pyplot.scatter(X_train[row_ix, 0], X_train[row_ix, 1], label=str(label))
pyplot.legend()
pyplot.show()

"""Shuffling the data"""

from sklearn.utils import shuffle
X_train, y_train = shuffle(X_train, y_train, random_state=0)

"""Analysis functions:"""

import math
def Accuracy(tp,tn,fp,fn):
  if (tp+tn+fp+fn)!=0:
    acc=(tp+tn)/(tp+tn+fp+fn)
  else:
    acc=0
  return acc
def Sensitivity(tp,tn,fp,fn):
  if (tp+fn)!=0:
    sen=tp/(tp+fn)
  else:
    sen=0
  return sen
def Specificity(tp,tn,fp,fn):
  if (tn+fp)!=0:
   spec=tn/(tn+fp)
  else:
    spec=0
  return spec
def False_Discovery_Rate(tp,tn,fp,fn):
  if (fp+tp)!=0:
    FDR=fp/(fp+tp)
  else:
    FDR=0
  return FDR
def False_Omission_Rate(tp,tn,fp,fn):
  if (fn+tn)!=0:
    FOR=fn/(fn+tn)
  else:
    FOR=0
  return FOR
def Mattews_Correlation_Coefficient(tp,tn,fp,fn):
  if (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)!=0:
    MCC=((tp*tn)-(fp*fn))/((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))**(0.5)
  else:
    MCC=0
  return MCC

"""1.KNN Classifier with k=3 and k=5"""

# https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix

import numpy as np
from sklearn.model_selection import KFold
X = np.asarray(X_train)
y = np.asarray(y_train)
kf = KFold(n_splits=5)
kf.get_n_splits(X)
Accuracy_foldwise=[]
Accuracy_foldwise1=[]
i1=[]
i=0
for training_index, valid_index in kf.split(X,y):
    # print("TRAIN:", train_index, "TEST:", test_index)
    i+=1
    X_training, X_valid = X[training_index], X[valid_index]
    y_training, y_valid = y[training_index], y[valid_index]
    neigh = KNeighborsClassifier(n_neighbors=5)
    neigh1 = KNeighborsClassifier(n_neighbors=3)
    neigh.fit(X_training, y_training)
    neigh1.fit(X_training, y_training)
    pred=neigh.predict(X_valid)
    pred1=neigh1.predict(X_valid)
    print("fold ",i,"for k=5 : ",accuracy_score(y_valid,pred))
    print("fold ",i,"for k=3 : ",accuracy_score(y_valid,pred1))
    print('\n')
    i1.append(i)
    Accuracy_foldwise.append(accuracy_score(y_valid,pred))
    Accuracy_foldwise1.append(accuracy_score(y_valid,pred1))
neigh.fit(X, y)
neigh1.fit(X, y)
y_pred=neigh.predict(X_test)
y_pred1=neigh1.predict(X_test)
tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()
tn1, fp1, fn1, tp1 = confusion_matrix(y_test,y_pred1).ravel()
print("overall accuracy from k folds from TRAIN data when k=5: ",sum(Accuracy_foldwise)/len(Accuracy_foldwise))
print("--------------analysis on test data------------")
print("Accuracy: ",Accuracy(tp,tn,fp,fn))
print("Sensitivity: ",Sensitivity(tp,tn,fp,fn))
print("Specificity:",Specificity(tp,tn,fp,fn))
print("False_Discovery_Rate:",False_Discovery_Rate(tp,tn,fp,fn))
print("False_Omission_Rate:",False_Omission_Rate(tp,tn,fp,fn))
print("Mattews_Correlation_Coefficient:",Mattews_Correlation_Coefficient(tp,tn,fp,fn))



print("overall accuracy from k folds from TRAIN data when k=3: ",sum(Accuracy_foldwise1)/len(Accuracy_foldwise1))
print("--------------analysis on test data------------")
print("Accuracy: ",Accuracy(tp1,tn1,fp1,fn1))
print("Sensitivity: ",Sensitivity(tp1,tn1,fp1,fn1))
print("Specificity:",Specificity(tp1,tn1,fp1,fn1))
print("False_Discovery_Rate:",False_Discovery_Rate(tp1,tn1,fp1,fn1))
print("False_Omission_Rate:",False_Omission_Rate(tp1,tn1,fp1,fn1))
print("Mattews_Correlation_Coefficient:",Mattews_Correlation_Coefficient(tp1,tn1,fp1,fn1))

neigh

neigh1

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)

import seaborn as sns
sns.heatmap(cm,annot=True)
plt.savefig('KNN.png')
plt.title("Graph for k=5")
plt.show()

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred1)

import seaborn as sns
sns.heatmap(cm,annot=True)
plt.savefig('KNN1.png')
plt.title("Graph for k=3")

plt.plot(i1,Accuracy_foldwise, label = "Efficiency vs K")
plt.legend()
plt.title("Graph of accuracy v/s k-fold for k=5")
plt.show()

plt.plot(i1,Accuracy_foldwise1, label = "Efficiency vs K")
plt.legend()
plt.title("Graph of accuracy v/s k-fold for k=3")
plt.show()

from sklearn.metrics import roc_auc_score, auc
from sklearn.metrics import roc_curve
roc_log = roc_auc_score(y_test,y_pred)
false_positive_rate, true_positive_rate, threshold = roc_curve(y_test,y_pred,)
area_under_curve = auc(false_positive_rate, true_positive_rate)

plt.plot([0, 1], [0, 1], 'r--')
plt.plot(false_positive_rate, true_positive_rate, label='AUC = {:.3f}'.format(area_under_curve))
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve for k=5')
plt.legend(loc='best')
plt.show()
#plt.savefig(ROC_PLOT_FILE, bbox_inches='tight')
plt.close()

from sklearn.metrics import roc_auc_score, auc
from sklearn.metrics import roc_curve
roc_log = roc_auc_score(y_test,y_pred1)
false_positive_rate, true_positive_rate, threshold = roc_curve(y_test,y_pred1,)
area_under_curve = auc(false_positive_rate, true_positive_rate)

plt.plot([0, 1], [0, 1], 'r--')
plt.plot(false_positive_rate, true_positive_rate, label='AUC = {:.3f}'.format(area_under_curve))
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve for k=3')
plt.legend(loc='best')
plt.show()
#plt.savefig(ROC_PLOT_FILE, bbox_inches='tight')
plt.close()

import csv
rows = zip(id_test,y_pred)
with open("knn_k=5.csv", "w") as f:
  writer = csv.writer(f)
  writer.writerow(["id","category"])
  for row in rows:
    writer.writerow(row)

import csv
rows = zip(id_test,y_pred1)
with open("knn_k=3.csv", "w") as f:
  writer = csv.writer(f)
  writer.writerow(["id","category"])
  for row in rows:
    writer.writerow(row)

"""2.SVM"""

import numpy as np
from sklearn.svm import SVC
from sklearn.model_selection import KFold
X = np.asarray(X_train)
y = np.asarray(y_train)
kf = KFold(n_splits=5)
kf.get_n_splits(X)
Accuracy_foldwise=[]
i1=[]
i=0
for training_index, valid_index in kf.split(X,y):
    # print("TRAIN:", train_index, "TEST:", test_index)
    i+=1
    X_training, X_valid = X[training_index], X[valid_index]
    y_training, y_valid = y[training_index], y[valid_index]
    # clfsvc = SVC(C=200,gamma='scale',random_state=42)
    clfsvc=SVC(C=200)
    clfsvc.fit(X_training, y_training)
    pred=clfsvc.predict(X_valid)
    print("fold ",i,": ",accuracy_score(y_valid,pred))
    i1.append(i)
    Accuracy_foldwise.append(accuracy_score(y_valid,pred))
print("overall accuracy: ",sum(Accuracy_foldwise)/len(Accuracy_foldwise))
clfsvc.fit(X, y)
y_pred=clfsvc.predict(X_test)
tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()
print("overall accuracy from k folds from TRAIN data: ",sum(Accuracy_foldwise)/len(Accuracy_foldwise))
print("--------------analysis on test data------------")
print("Accuracy: ",Accuracy(tp,tn,fp,fn))
print("Sensitivity: ",Sensitivity(tp,tn,fp,fn))
print("Specificity:",Specificity(tp,tn,fp,fn))
print("False_Discovery_Rate:",False_Discovery_Rate(tp,tn,fp,fn))
print("False_Omission_Rate:",False_Omission_Rate(tp,tn,fp,fn))
print("Mattews_Correlation_Coefficient:",Mattews_Correlation_Coefficient(tp,tn,fp,fn))
# print("Accuracy:",Accuracy(tp,tn,fp,fn))

clfsvc

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)

import seaborn as sns
sns.heatmap(cm,annot=True)
plt.savefig('SVM.png')

plt.plot(i1,Accuracy_foldwise, label = "Efficiency vs K")
plt.legend()
plt.show()

from sklearn.metrics import roc_auc_score, auc
from sklearn.metrics import roc_curve
roc_log = roc_auc_score(y_test,y_pred)
false_positive_rate, true_positive_rate, threshold = roc_curve(y_test,y_pred,)
area_under_curve = auc(false_positive_rate, true_positive_rate)

plt.plot([0, 1], [0, 1], 'r--')
plt.plot(false_positive_rate, true_positive_rate, label='AUC = {:.3f}'.format(area_under_curve))
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.legend(loc='best')
plt.show()
#plt.savefig(ROC_PLOT_FILE, bbox_inches='tight')
plt.close()

import csv
rows = zip(id_test,y_pred)
with open("svm.csv", "w") as f:
  writer = csv.writer(f)
  writer.writerow(["id","category"])
  for row in rows:
    writer.writerow(row)

"""LightGBM  MODEL:"""

import numpy as np
from sklearn.model_selection import KFold
from lightgbm import LGBMClassifier
X = np.asarray(X_train)
y = np.asarray(y_train)
kf = KFold(n_splits=5)
kf.get_n_splits(X)
Accuracy_foldwise=[]
i1=[]
i=0
for training_index, valid_index in kf.split(X,y):
    # print("TRAIN:", train_index, "TEST:", test_index)
    i+=1
    X_training, X_valid = X[training_index], X[valid_index]
    y_training, y_valid = y[training_index], y[valid_index]
    lgbm = LGBMClassifier(random_state=42, reg_alpha=0.018)
    lgbm.fit(X_training, y_training)
    pred=lgbm.predict(X_valid)
    print("fold ",i,": ",accuracy_score(y_valid,pred))
    i1.append(i)
    Accuracy_foldwise.append(accuracy_score(y_valid,pred))
lgbm.fit(X, y)
y_pred=lgbm.predict(X_test)
tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()
print("overall accuracy from k folds from TRAIN data: ",sum(Accuracy_foldwise)/len(Accuracy_foldwise))
print("--------------analysis on test data------------")
print("Accuracy: ",Accuracy(tp,tn,fp,fn))
print("Sensitivity: ",Sensitivity(tp,tn,fp,fn))
print("Specificity:",Specificity(tp,tn,fp,fn))
print("False_Discovery_Rate:",False_Discovery_Rate(tp,tn,fp,fn))
print("False_Omission_Rate:",False_Omission_Rate(tp,tn,fp,fn))
print("Mattews_Correlation_Coefficient:",Mattews_Correlation_Coefficient(tp,tn,fp,fn))

lgbm

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)

import seaborn as sns
sns.heatmap(cm,annot=True)
plt.savefig('lgbm.png')

plt.plot(i1,Accuracy_foldwise, label = "Efficiency vs K")
plt.legend()
plt.show()

from sklearn.metrics import roc_auc_score, auc
from sklearn.metrics import roc_curve
roc_log = roc_auc_score(y_test,y_pred)
false_positive_rate, true_positive_rate, threshold = roc_curve(y_test,y_pred,)
area_under_curve = auc(false_positive_rate, true_positive_rate)

plt.plot([0, 1], [0, 1], 'r--')
plt.plot(false_positive_rate, true_positive_rate, label='AUC = {:.3f}'.format(area_under_curve))
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.legend(loc='best')
plt.show()
#plt.savefig(ROC_PLOT_FILE, bbox_inches='tight')
plt.close()

import csv
rows = zip(id_test,y_pred)
with open("lgbm.csv", "w") as f:
  writer = csv.writer(f)
  writer.writerow(["id","category"])
  for row in rows:
    writer.writerow(row)

"""Gaussian process RBF:"""

import numpy as np
from sklearn.model_selection import KFold

from sklearn.gaussian_process import GaussianProcessClassifier
from sklearn.gaussian_process.kernels import RBF
X = np.asarray(X_train)
y = np.asarray(y_train)
kf = KFold(n_splits=5)
kf.get_n_splits(X)
Accuracy_foldwise=[]
i1=[]
i=0
for training_index, valid_index in kf.split(X,y):
    # print("TRAIN:", train_index, "TEST:", test_index)
    i+=1
    X_training, X_valid = X[training_index], X[valid_index]
    y_training, y_valid = y[training_index], y[valid_index]
    kernel = 1.0 * RBF(1.0)
    
    gpc = GaussianProcessClassifier(kernel=kernel,random_state=0)
    gpc.fit(X_training, y_training)
    pred=gpc.predict(X_valid)
    print("fold ",i,": ",accuracy_score(y_valid,pred))
    i1.append(i)
    Accuracy_foldwise.append(accuracy_score(y_valid,pred))
gpc.fit(X, y)
y_pred=gpc.predict(X_test)
tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()
print("overall accuracy from k folds from TRAIN data: ",sum(Accuracy_foldwise)/len(Accuracy_foldwise))
print("--------------analysis on test data------------")
print("Accuracy: ",Accuracy(tp,tn,fp,fn))
print("Sensitivity: ",Sensitivity(tp,tn,fp,fn))
print("Specificity:",Specificity(tp,tn,fp,fn))
print("False_Discovery_Rate:",False_Discovery_Rate(tp,tn,fp,fn))
print("False_Omission_Rate:",False_Omission_Rate(tp,tn,fp,fn))
print("Mattews_Correlation_Coefficient:",Mattews_Correlation_Coefficient(tp,tn,fp,fn))

gpc

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)

import seaborn as sns
sns.heatmap(cm,annot=True)
plt.savefig('gpr.png')

plt.plot(i1,Accuracy_foldwise, label = "Efficiency vs K")
plt.legend()
plt.show()

from sklearn.metrics import roc_auc_score, auc
from sklearn.metrics import roc_curve
roc_log = roc_auc_score(y_test,y_pred)
false_positive_rate, true_positive_rate, threshold = roc_curve(y_test,y_pred,)
area_under_curve = auc(false_positive_rate, true_positive_rate)

plt.plot([0, 1], [0, 1], 'r--')
plt.plot(false_positive_rate, true_positive_rate, label='AUC = {:.3f}'.format(area_under_curve))
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.legend(loc='best')
plt.show()
#plt.savefig(ROC_PLOT_FILE, bbox_inches='tight')
plt.close()

import csv
rows = zip(id_test,y_pred)
with open("gpr.csv", "w") as f:
  writer = csv.writer(f)
  writer.writerow(["id","category"])
  for row in rows:
    writer.writerow(row)

"""**Using MLP**"""

from sklearn.neural_network import MLPClassifier
X = np.asarray(X_train)
y = np.asarray(y_train)
kf = KFold(n_splits=5)
kf.get_n_splits(X)
Accuracy_foldwise=[]
i1=[]
i=0
for training_index, valid_index in kf.split(X,y):
    # print("TRAIN:", train_index, "TEST:", test_index)
    i+=1
    X_training, X_valid = X[training_index], X[valid_index]
    y_training, y_valid = y[training_index], y[valid_index]
    clf=MLPClassifier(hidden_layer_sizes=(10,2), activation='relu', solver='adam', alpha=1e-5, batch_size=50, learning_rate='adaptive', 
                      learning_rate_init=0.001, power_t=0.5, max_iter=500, tol=0.0001)
    clf.fit(X,y)
    pred=clf.predict(X_valid)
    print("fold ",i,": ",accuracy_score(y_valid,pred))
    i1.append(i)
    Accuracy_foldwise.append(accuracy_score(y_valid,pred))
clf.fit(X, y)
y_pred=lgbm.predict(X_test)
tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()
print("overall accuracy from k folds from TRAIN data: ",sum(Accuracy_foldwise)/len(Accuracy_foldwise))
print("--------------analysis on test data------------")
print("Accuracy: ",Accuracy(tp,tn,fp,fn))
print("Sensitivity: ",Sensitivity(tp,tn,fp,fn))
print("Specificity:",Specificity(tp,tn,fp,fn))
print("False_Discovery_Rate:",False_Discovery_Rate(tp,tn,fp,fn))
print("False_Omission_Rate:",False_Omission_Rate(tp,tn,fp,fn))
print("Mattews_Correlation_Coefficient:",Mattews_Correlation_Coefficient(tp,tn,fp,fn))

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)

import seaborn as sns
sns.heatmap(cm,annot=True)
plt.savefig('mlp.png')

plt.plot(i1,Accuracy_foldwise, label = "Efficiency vs K")
plt.legend()
plt.show()

from sklearn.metrics import roc_auc_score, auc
from sklearn.metrics import roc_curve
roc_log = roc_auc_score(y_test,y_pred)
false_positive_rate, true_positive_rate, threshold = roc_curve(y_test,y_pred,)
area_under_curve = auc(false_positive_rate, true_positive_rate)

plt.plot([0, 1], [0, 1], 'r--')
plt.plot(false_positive_rate, true_positive_rate, label='AUC = {:.3f}'.format(area_under_curve))
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.legend(loc='best')
plt.show()
#plt.savefig(ROC_PLOT_FILE, bbox_inches='tight')
plt.close()

import csv
rows = zip(id_test,y_pred)
with open("mlp.csv", "w") as f:
  writer = csv.writer(f)
  writer.writerow(["id","category"])
  for row in rows:
    writer.writerow(row)

"""**Developing Models using Deep Learning Techniques**"""

from keras.layers.recurrent import LSTM
from sklearn.model_selection import StratifiedKFold
from keras.models import Sequential
import numpy as np
from keras.layers import Dense, Dropout, Activation
from keras.callbacks import EarlyStopping
from keras.callbacks import ModelCheckpoint
from keras.callbacks import ReduceLROnPlateau

#define 5-fold cross validation
kfold=StratifiedKFold(n_splits=5,shuffle=True, random_state=0)
#kfold = KFold(n_splits=10)
X_reshape= np.reshape(X, (X.shape[0], 1, X.shape[1]))
X_test_reshape=np.reshape(X_test, (X_test.shape[0],1,X_test.shape[1]))

"""**Using LSTM**"""

cvscores=[]
i1=[]
i=0
for train,test in kfold.split(X,y):
  i=i+1
  model = Sequential()
  model.add(LSTM((32),input_shape=(1,20),activation='relu',return_sequences=True))

  model.add(LSTM(16,activation='relu'))
 
  model.add(Dense(2,activation='softmax'))
 
  i1.append(i)
  #compile the model
  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
  earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')
  mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_acc', mode='max')
  reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, epsilon=1e-4, mode='min')
  #train the model
  history=model.fit(X_reshape[train], y[train], epochs=100,batch_size=5,callbacks=[earlyStopping,mcp_save],validation_data=(X_reshape[test],y[test]))

  #Evaluate the model
  scores = model.evaluate(X_reshape[test], y[test], verbose=0)
  print('Accuracy: %.2f' % (scores[1]*100))
  cvscores.append(scores[1]*100)
  predicted_value=model.predict_classes(X_reshape[test])

print("%.2f%% (+/-%.2f%%)" % (np.mean(cvscores),np.std(cvscores)))

model.fit(X_reshape, y)
y_pred=model.predict_classes(X_test_reshape)
tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()
print("--------------analysis on test data------------")
print("Accuracy: ",Accuracy(tp,tn,fp,fn))
print("Sensitivity: ",Sensitivity(tp,tn,fp,fn))
print("Specificity:",Specificity(tp,tn,fp,fn))
print("False_Discovery_Rate:",False_Discovery_Rate(tp,tn,fp,fn))
print("False_Omission_Rate:",False_Omission_Rate(tp,tn,fp,fn))
print("Mattews_Correlation_Coefficient:",Mattews_Correlation_Coefficient(tp,tn,fp,fn))

import matplotlib.pyplot as plt
plt.scatter(range(len(predicted_value)),predicted_value,c='r')
plt.scatter(range(len(predicted_value)),y[test],c='g')
plt.title('Graph showing actual data v/s predicted data')
plt.show()

plt.plot(history.history['accuracy'])
plt.title('Graph showing accuracy v/s epochs')
plt.show()

plt.plot(history.history['loss'])
plt.title('Graph showing loss v/s epochs')
plt.show()

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)

import seaborn as sns
sns.heatmap(cm,annot=True)
plt.savefig('LSTM.png')

plt.plot(i1,cvscores, label = "Efficiency vs K")
plt.legend()
plt.show()

from sklearn.metrics import roc_auc_score, auc
from sklearn.metrics import roc_curve
roc_log = roc_auc_score(y_test,y_pred)
false_positive_rate, true_positive_rate, threshold = roc_curve(y_test,y_pred,)
area_under_curve = auc(false_positive_rate, true_positive_rate)

plt.plot([0, 1], [0, 1], 'r--')
plt.plot(false_positive_rate, true_positive_rate, label='AUC = {:.3f}'.format(area_under_curve))
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.legend(loc='best')
plt.show()
#plt.savefig(ROC_PLOT_FILE, bbox_inches='tight')
plt.close()

import csv
rows = zip(id_test,y_test)
with open("lstm.csv", "w") as f:
  writer = csv.writer(f)
  writer.writerow(["id","category"])
  for row in rows:
    writer.writerow(row)

"""**Using Dense Sequential neural networks**"""

cvscores=[]
i1=[]
i=0
for train,test in kfold.split(X,y):
  i=i+1
  model = Sequential()
  model.add(Dense(15,input_dim=(20),activation='relu'))
  model.add(Dense(8,activation='relu'))
 
  model.add(Dense(2,activation='sigmoid'))
 
  i1.append(i)
  #compile the model
  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
  earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')
  mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_acc', mode='max',verbose=True)
  reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, epsilon=1e-4, mode='min')
  
  #train the model
  history=model.fit(X[train], y[train], epochs=120,batch_size=20,callbacks=[earlyStopping,mcp_save],validation_data=(X[test],y[test]))

  #Evaluate the model
  scores = model.evaluate(X[test], y[test], verbose=0)
  print('Accuracy: %.2f' % (scores[1]*100))
  cvscores.append(scores[1]*100)
  predicted_value=model.predict_classes(X[test])

print("%.2f%% (+/-%.2f%%)" % (np.mean(cvscores),np.std(cvscores)))

model.fit(X, y)
y_pred=model.predict_classes(X_test)
tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()
print("--------------analysis on test data------------")
print("Accuracy: ",Accuracy(tp,tn,fp,fn))
print("Sensitivity: ",Sensitivity(tp,tn,fp,fn))
print("Specificity:",Specificity(tp,tn,fp,fn))
print("False_Discovery_Rate:",False_Discovery_Rate(tp,tn,fp,fn))
print("False_Omission_Rate:",False_Omission_Rate(tp,tn,fp,fn))
print("Mattews_Correlation_Coefficient:",Mattews_Correlation_Coefficient(tp,tn,fp,fn))

"""**Graph showing actual data v/s predicted data**"""

plt.scatter(range(len(predicted_value)),predicted_value,c='r')
plt.scatter(range(len(predicted_value)),y[test],c='g')
plt.title(('Graph showing actual data v/s predicted data'))
plt.show()

plt.plot(history.history['accuracy'])
plt.title('Graph showing accuracy v/s epochs')
plt.show()

"""d**Graph showing Loss v/s Epochs**"""

plt.plot(history.history['loss'])
plt.title('Graph showing loss v/s epochs')
plt.show()

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)

import seaborn as sns
sns.heatmap(cm,annot=True)
plt.savefig('NN.png')

plt.plot(i1,cvscores, label = "Efficiency vs K")
plt.legend()
plt.show()

from sklearn.metrics import roc_auc_score, auc
from sklearn.metrics import roc_curve
roc_log = roc_auc_score(y_test,y_pred)
false_positive_rate, true_positive_rate, threshold = roc_curve(y_test,y_pred,)
area_under_curve = auc(false_positive_rate, true_positive_rate)

plt.plot([0, 1], [0, 1], 'r--')
plt.plot(false_positive_rate, true_positive_rate, label='AUC = {:.3f}'.format(area_under_curve))
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.legend(loc='best')
plt.show()
#plt.savefig(ROC_PLOT_FILE, bbox_inches='tight')
plt.close()

import csv
rows = zip(id_test,y_pred)
with open("NN.csv", "w") as f:
  writer = csv.writer(f)
  writer.writerow(["id","category"])
  for row in rows:
    writer.writerow(row)